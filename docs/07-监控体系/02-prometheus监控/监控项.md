# 一、监控基本原理

## Prometheus监控架构

无论是业务应用还是Kubernetes系统组件，只要提供了满足标准Prometheus格式的metrics API，即可被Prometheus采集监控。

## 标准监控接口

- **路径**: `/metrics`
- **协议**: HTTP/HTTPS
- **格式**: Prometheus文本格式
- **示例组件**:
  - Prometheus自身: `:9090/metrics`
  - CoreDNS: `:9153/metrics`
  - Kubernetes API Server: `:6443/metrics`

### prometheus

```bash
[root@k8s-master-10 /kube/prometheus]#kubectl -n monitor exec -it prometheus-6497d6f8bc-qp9tx -- sh
Defaulted container "prometheus" out of: prometheus, change-permission-of-directory (init)
/prometheus $ netstat -tunlp
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 :::9090                 :::*                    LISTEN      1/prometheus
/prometheus $ 


# 程序主动暴露一些metrics API、以及端口，是程序开发者定义好的，我们直接可以去访问
```

### CoreDNS

k8s本身资源也一样，因为暴露metricsAPI，交给prometheus已经是成熟且固定的方案。

```bash
[root@k8s-master-10 /kube/prometheus]#kubectl -n kube-system get po -owide|grep dns
coredns-6b4b464477-cp2bq                1/1     Running   4 (21h ago)   4d23h   10.2.3.78   k8s-node-11     <none>           <none>
coredns-6b4b464477-t8vkn                1/1     Running   4 (21h ago)   4d23h   10.2.0.11   k8s-master-10   <none>           <none>
[root@k8s-master-10 /kube/prometheus]#kubectl -n kube-system get svc -o wide
NAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE     SELECTOR
kube-dns   ClusterIP   10.1.0.10    <none>        53/UDP,53/TCP,9153/TCP   5d15h   k8s-app=kube-dns
[root@k8s-master-10 /kube/prometheus]#curl  -s 10.1.0.10:9153/metrics | tail
process_resident_memory_bytes 5.9273216e+07
# HELP process_start_time_seconds Start time of the process since unix epoch in seconds.
# TYPE process_start_time_seconds gauge
process_start_time_seconds 1.7696337756e+09
# HELP process_virtual_memory_bytes Virtual memory size in bytes.
# TYPE process_virtual_memory_bytes gauge
process_virtual_memory_bytes 7.83007744e+08
# HELP process_virtual_memory_max_bytes Maximum amount of virtual memory available in bytes.
# TYPE process_virtual_memory_max_bytes gauge
process_virtual_memory_max_bytes 1.8446744073709552e+19
```

#### 添加至监控配置

```
kubectl -n monitor edit configmap prometheus-config
```

```bash
    scrape_configs:
      # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
      - job_name: "prometheus"

        # metrics_path defaults to '/metrics'
        # scheme defaults to 'http'.

        static_configs:
          - targets: ["localhost:9090"]
            labels:
              app: "prometheus"

      - job_name: "core_dns"
        static_configs:
          - targets: ["10.1.0.10:9153"]
            labels:
              namespace: 'kube-system'
              service: 'kube-dns'
```

#### 热更新 reload 配置

```bash
kubectl -n monitor get po -o wide
NAME                          READY   STATUS    RESTARTS      AGE   IP          NODE          NOMINATED NODE   READINESS GATES
prometheus-6497d6f8bc-qp9tx   1/1     Running   1 (18h ago)   18h   10.2.2.78   k8s-node-12   <none>           <none>

curl -X POST 10.2.2.78:9090/-/reload
```

#### 验证 查看target

![image-20260129154625875](./assets/image-20260129154625875.png)

#### 检查样本

![image-20260129155045928](./assets/image-20260129155045928.png)

---

# 二、监控目标添加实践

## 常用监控对象

### 2.1 CoreDNS监控配置

```yaml
# prometheus.yml 配置片段
scrape_configs:
  - job_name: 'coredns'
    static_configs:
    - targets: ['10.96.0.10:9153']
```

**验证方法**:

```sh
# 查看CoreDNS服务
kubectl -n kube-system get svc kube-dns
# 访问指标接口
curl 10.1.0.10:9153/metrics | tail
```

### 2.2 Kubernetes API Server监控配置

API Server使用HTTPS协议，需要认证授权：

```bash
kubectl get svc kubernetes -n default
NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.1.0.1     <none>        443/TCP   5d16h
kubectl edit
```

```yaml
      - job_name: 'kubernetes-apiserver'
        static_configs:
        - targets: ['10.1.0.1']
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
```

**手动验证**:

```sh
# 获取token
kubectl -n monitor create token prometheus
# 访问API Server metrics
curl -s -k -H "Authorization: Bearer eyJhbGciOiJSUzI1NiIsImtpZCI6IndQcEh4NkFyYVF3SVc2Z0JxY01lV2ZicnZqbjNlQV9RNmFwMEphSjZxbW8ifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNzY5Njc4MTIxLCJpYXQiOjE3Njk2NzQ1MjEsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJtb25pdG9yIiwic2VydmljZWFjY291bnQiOnsibmFtZSI6InByb21ldGhldXMiLCJ1aWQiOiJkMmU0Y2VjNC0zODhiLTQ3ZDUtOTkwNS0zNzRjMDBmZDIyMGEifX0sIm5iZiI6MTc2OTY3NDUyMSwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Om1vbml0b3I6cHJvbWV0aGV1cyJ9.DAYgPn8eDpOPGEFW0kGwXAmLfmvwPURpTGl-RQ6IX6y4SRfHZ6D0mKiOcTaTNEnrEaQmu_G4GI0GqKeAHZgpq0dTU8xLDhAo_68RXUBm5r_MME4U1DNeDOMJ49mfAB9hTJbusnhua8J88MgQOxRkhPtqZm03uWv2bgy3cYGz_Bd4rh_fOJSMAG2-HtyaCK9b4RAiPAiiHqLdY0LpEPkTOnIgUk0096Tv0RUB8lhDOLFzA9lNiJ-JnxJqu4LHV5IeE_U49Vn9XqBjeqZUjOuckUE_dURReHhXHFfLTpJTvlRPYmMlFuOZTH7-NHnMNGOyn5EtPPnTVx120pU_1LklAw" https://10.1.0.1:443/metrics | tail
```

### 2.3 配置热更新

```
# 触发热重载 svc或者podIP
curl -X POST 10.1.218.72:9090/-/reload
```

![image-20260129162356347](./assets/image-20260129162356347.png)

---

# 三、常用监控对象分类

## 3.1 内部系统组件

- kube-apiserver
- kube-scheduler
- kube-controller-manager
- kube-dns/coredns

## 3.2 Kubernetes节点

- CPU、内存、磁盘、网络
- 节点健康状况

## 3.3 业务容器基础指标

- CPU使用率
- 内存使用量
- 磁盘I/O
- 网络流量

## 3.4 业务容器业务指标

- 应用自定义metrics
- 通过`/metrics` API暴露

## 3.5 编排级指标

- Deployment状态
- StatefulSet状态
- DaemonSet状态
- 资源请求/限制

---

# 四、节点级监控（Node Exporter）

Node Exporter是一个官方的Prometheus exporter，它可以从操作系统中提取各种指标，例如CPU使用率、内存使用率、磁盘使用率等等。Node Exporter本质上是一个二进制文件，需要在每个节点上安装并运行。

## 4.1 DaemonSet部署

```bash
每个节点都需要监控，因此可以使用DaemonSet类型来管理node_exporter
添加节点的容忍配置
挂载宿主机中的系统文件信息

Prometheus使用Node Exporter来监控节点。
Node Exporter是一个官方的Prometheus exporter，它可以从操作系统中提取各种指标，例如CPU使用率、内存使用率、磁盘使用率等等。Node Exporter本质上是一个二进制文件，需要在每个节点上安装并运行。

Node Exporter运行起来了，Prometheus就可以通过HTTP协议获取到节点的各种指标，并将这些指标存储到自己的时间序列数据库中。然后，就可以使用Prometheus提供的查询语言PromQL对这些指标进行查询和分析了。
```

```yaml
# node-exporter.yml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: node-exporter
  namespace: monitor
  labels:
    app: node-exporter
spec:
  selector:
    matchLabels:
      app: node-exporter
  template:
    metadata:
      labels:
        app: node-exporter
    spec:
      hostPID: true
      hostIPC: true
      hostNetwork: true
      nodeSelector:
        kubernetes.io/os: linux
      containers:
      - name: node-exporter
        image: prom/node-exporter:v1.10.2
        args:
        - --web.listen-address=$(HOSTIP):9100
        - --path.procfs=/host/proc
        - --path.sysfs=/host/sys
        - --path.rootfs=/host/root
        ports:
        - containerPort: 9100
        env:
        - name: HOSTIP
          valueFrom:
            fieldRef:
              fieldPath: status.hostIP
        volumeMounts:
        - name: proc
          mountPath: /host/proc
        - name: sys
          mountPath: /host/sys
        - name: root
          mountPath: /host/root
      tolerations:
      - operator: "Exists"
      volumes:
      - name: proc
        hostPath:
          path: /proc
      - name: sys
        hostPath:
          path: /sys
      - name: root
        hostPath:
          path: /
```

DaemonSet定义了如何创建Pod，并保证每个节点上都会有一个运行着Node Exporter的Pod。

在容器定义中，使用了Prometheus官方提供的node-exporter镜像，并指定了需要暴露的端口号和一些参数，例如路径和忽略的文件系统类型等等。容器使用了hostNetwork模式，以便在Pod中直接访问节点上的网络。此外，容器也挂载了节点上的一些目录，例如/proc、/sys和/root等等，以便从节点中获取指标。

## 4.2 创建与验证

```sh
kubectl apply -f node_exporter.yml 
# 查看运行状态
kubectl -n monitor get po -owide | grep node-exporter

# 访问指标接口
curl -s 10.0.0.12:9100/metrics | tail

# 查看节点内存指标
curl -s 10.0.0.10:9100/metrics | grep node_memory_MemTotal_bytes
curl -s 10.0.0.11:9100/metrics | grep node_memory_MemTotal_bytes
curl -s 10.0.0.12:9100/metrics | grep node_memory_MemTotal_bytes
```

## 4.3添加到target

ServiceDiscovery动态发现目标的机制

ServiceDiscovery和static_config都是Prometheus中用于配置target列表的机制，但它们之间有一些区别。

静态配置（static_config）是手动定义的target列表，您需要手动添加或删除每个目标。这意味着当集群中的节点增加或删除时，您需要手动更新静态配置文件以添加或删除节点。这对于较小的集群可能是可行的，但对于规模较大的集群而言，手动维护静态配置文件可能会变得非常困难。

相比之下，ServiceDiscovery是一种动态发现目标的机制，它允许Prometheus自动发现并监视与其连接的所有目标。ServiceDiscovery的工作方式是通过查询指定的服务注册表或API，来获取要监视的目标列表。当服务注册表或API发生更改时，Prometheus将自动检测到更改并更新其目标列表。这使得ServiceDiscovery非常适合用于动态环境，例如Kubernetes集群。

因此，ServiceDiscovery和静态配置之间的主要区别在于它们如何管理目标列表。静态配置需要手动添加和删除目标，而ServiceDiscovery会自动发现目标并自动更新列表。在许多情况下，使用ServiceDiscovery会更加方便和可扩展，特别是在动态环境中，而静态配置适用于静态环境或小型集群。

---

# 五、服务发现与Relabeling

## 5.1 静态配置 vs 服务发现

| 特性     | 静态配置           | 服务发现     |
| :------- | :----------------- | :----------- |
| 管理方式 | 手动配置           | 自动发现     |
| 扩展性   | 适合小集群         | 适合大集群   |
| 维护成本 | 节点变化需手动更新 | 自动适应变化 |

## 5.2 Prometheus支持的Kubernetes服务发现

1. **Node**: 发现集群节点
2. **Service**: 发现Service
3. **Pod**: 发现Pod
4. **Endpoints**: 发现Endpoints
5. **Ingress**: 发现Ingress资源

## 5.3 Node Exporter服务发现配置

Prometheus的node类型的服务发现模式，默认是和kubelet的10250绑定的。

```bash
kubectl -n monitor edit configmap prometheus-config
curl -X POST 10.1.218.72:9090/-/reload
```

```yaml
      - job_name: 'kubernetes-sd-node-exporter'
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
        - source_labels: [__address__]
          regex: '(.*):10250'
          replacement: '${1}:9100'
          target_label: __address__
          action: replace
```

### 对比两个端口的用途

| 端口  | 组件          | 提供指标                                | 协议  | 是否需要认证     |
| :---- | :------------ | :-------------------------------------- | :---- | :--------------- |
| 10250 | kubelet       | kubelet自身指标、cAdvisor容器指标       | HTTPS | 需要Bearer Token |
| 9100  | node-exporter | 节点系统指标（CPU、内存、磁盘、网络等） | HTTP  | 不需要认证       |

![image-20260129172846377](./assets/image-20260129172846377.png)

![image-20260129172828037](./assets/image-20260129172828037.png)

## 5.4 容器指标采集（cAdvisor）

cAdvisor（Container Advisor）是一个由Google开源的容器监控代理程序，用于收集和分析容器的资源使用情况。它可以监控容器的CPU、内存、磁盘和网络等资源使用情况，并提供有关容器的性能指标、事件和警报等信息。

```
      - job_name: 'kubernetes-sd-cadvisor'
        kubernetes_sd_configs:
          - role: node
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - target_label: __metrics_path__
          replacement: /metrics/cadvisor
```

```bash
kubectl -n monitor edit configmaps prometheus-config
curl -X POST 10.1.218.72:9090/-/reload
```

![image-20260129194539233](./assets/image-20260129194539233.png)

## 5.5 kubelet指标采集

```
      - job_name: 'kubernetes-sd-kubelet'
        kubernetes_sd_configs:
          - role: node
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
```

```bash
kubectl -n monitor edit configmaps prometheus-config
curl -X POST 10.1.218.72:9090/-/reload
```

![image-20260129203140616](./assets/image-20260129203140616.png)

---

# 六、kube-state-metrics

（Kubernetes对象状态监控）

## 6.1 部署kube-state-metrics

```sh
# 下载并修改配置
wget https://github.com/kubernetes/kube-state-metrics/archive/refs/tags/v2.9.2.tar.gz
tar -xf kube-state-metrics-2.9.2
cd kube-state-metrics-2.9.2/examples/standard/

# 两个节点准备镜像 
nerdctl pull swr.cn-north-4.myhuaweicloud.com/ddn-k8s/registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.9.2
nerdctl tag swr.cn-north-4.myhuaweicloud.com/ddn-k8s/registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.9.2 registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.9.2

vim deployment.yaml  
vim service-account.yaml 
vim service.yaml修改命名空间
namespace: monitor

# 部署
kubectl apply -f .
```

## 6.2 基于Endpoints的服务发现

```
      - job_name: 'kubernetes-sd-endpoints'
        kubernetes_sd_configs:
          - role: endpoints
```

```bash
kubectl -n monitor edit configmaps prometheus-config
curl -X POST 10.1.218.72:9090/-/reload
```

![image-20260129220439007](./assets/image-20260129220439007.png)

可以发现，实际上endpoint这个类型，目标是去抓取整个集群中所有的命名空间的Endpoint列表，然后使用默认的/metrics进行数据抓取，我们可以通过查看集群中的所有ep列表来做对比：

```
kubectl get endpoints --all-namespaces
```

但是实际上并不是每个服务都已经实现了/metrics监控的，也不是每个实现了/metrics接口的服务都需要注册到Prometheus中。

---

# 七、基于Service的业务应用监控

## 7.1 自动发现机制

通过Service的annotations控制监控采集：

kubectl -n kube-system get svc kube-dns -o yaml

```yaml
apiVersion: v1
kind: Service
metadata:
  annotations:
    prometheus.io/scrape: "true"      # 是否采集
    prometheus.io/port: "9153"        # 采集端口
    prometheus.io/path: "/metrics"    # 默认采集路径
```

在Kubernetes中，可以使用Service的annotations声明来配置Prometheus的服务发现和监控。具体来说，Service对象的annotations中的键值对将转换为Prometheus中的标签（labels）。

```bash
名为"my-service"的Service对象添加了两个annotations标记。
"prometheus.io/scrape: 'true'"标记用于启用Prometheus的服务发现和监控
"prometheus.io/path: '/metrics'"标记则指定了自定义的采集路径。
意味着Prometheus会使用"/metrics"作为采集路径来获取名为"my-service"的Service对象的指标数据。
```

## 7.2 Prometheus配置模板

```yaml
      - job_name: 'kubernetes-sd-endpoints'
        kubernetes_sd_configs:
          - role: endpoints
        relabel_configs:
          # 只采集有prometheus.io/scrape=true注解的服务
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          
          # 自定义采集路径
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          
          # 自定义采集端口
          - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
            action: replace
            target_label: __address__
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
          
          # 添加Kubernetes标签
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_service_name]
            action: replace
            target_label: kubernetes_service_name
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: kubernetes_pod_name
```

```bash
kubectl -n monitor edit configmaps prometheus-config
curl -X POST 10.1.218.72:9090/-/reload
```

```bash
假设一个 Service 有这样的注解：
apiVersion: v1
kind: Service
metadata:
  name: my-app
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/path: "/custom-metrics"
    prometheus.io/port: "8080"
####
这些annotations会被Prometheus自动转换为标签（labels）：
prometheus.io/scrape → __meta_kubernetes_service_annotation_prometheus_io_scrape
prometheus.io/port → __meta_kubernetes_service_annotation_prometheus_io_port
prometheus.io/path → __meta_kubernetes_service_annotation_prometheus_io_path
1. 服务发现阶段
   ↓ 发现Kubernetes所有Services/Endpoints
   ↓ 提取annotations转换为元标签
   ↓ 得到: __meta_kubernetes_service_annotation_prometheus_io_path="/custom-metrics"

2. relabeling阶段
   ↓ 配置规则: 把元标签的值复制到内部标签
   ↓ 执行: __metrics_path__ = "/custom-metrics"

3. 采集阶段
   ↓ Prometheus看到: __metrics_path__ = "/custom-metrics"
   ↓ 实际访问: http://<target>/custom-metrics
```

## 7.3监控kube-state-metrics的service

```bash
修改kube-state-metrics的service
[root@k8s-master-10 /kube/prometheus/kube-state-metrics-2.9.2/examples/standard]#vim service.yaml 

apiVersion: v1
kind: Service
metadata:
  annotations:  
    prometheus.io/scrape: "true"  # 必须
    prometheus.io/port: "8080"  # 组件自身设计8080端口提供主要的 Kubernetes 集群状态指标
  labels:
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/version: 2.1.0
  name: kube-state-metrics
  namespace: monitor

[root@k8s-master-10 /kube/prometheus/kube-state-metrics-2.9.2/examples/standard]#kubectl apply -f .
clusterrolebinding.rbac.authorization.k8s.io/kube-state-metrics unchanged
clusterrole.rbac.authorization.k8s.io/kube-state-metrics unchanged
deployment.apps/kube-state-metrics unchanged
serviceaccount/kube-state-metrics unchanged
service/kube-state-metrics configured
```

![image-20260130000413305](./assets/image-20260130000413305.png)

![image-20260130000958239](./assets/image-20260130000958239.png)

---

# prometheus.yml总结

```bash
global:
  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  - /etc/prometheus/alert_rules.yml
  # - "first_rules.yml"
  # - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: "prometheus"
    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.
    static_configs:
      - targets: ["localhost:9090"]
        # The label name is added as a label `label_name=<label_value>` to any timeseries scraped from this config.
        labels:
          app: "prometheus"

  - job_name: "core_dns"
    static_configs:
      - targets: ["10.1.0.10:9153"]
        labels:
          namespace: 'kube-system'
          service: 'kube-dns'

  - job_name: 'kubernetes-apiserver'
    static_configs:
      - targets: ['10.1.0.1']
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

  - job_name: 'kubernetes-sd-node-exporter'
    kubernetes_sd_configs:
      - role: node
    relabel_configs:
      - source_labels: [__address__]
        regex: '(.*):10250'
        replacement: '${1}:9100'
        target_label: __address__
        action: replace

  - job_name: 'kubernetes-sd-cadvisor'
    kubernetes_sd_configs:
      - role: node
    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    relabel_configs:
      - target_label: __metrics_path__
        replacement: /metrics/cadvisor

  - job_name: 'kubernetes-sd-kubelet'
    kubernetes_sd_configs:
      - role: node
    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

  - job_name: 'kubernetes-sd-endpoints'
    kubernetes_sd_configs:
      - role: endpoints
    relabel_configs:
      # 只采集有prometheus.io/scrape=true注解的服务
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      
      # 自定义采集路径
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      
      # 自定义采集端口
      - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
        action: replace
        target_label: __address__
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
      
      # 添加Kubernetes标签
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_service_name]
        action: replace
        target_label: kubernetes_service_name
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name
```









# 常用服务的 Metrics 支持情况

## **原生支持 Prometheus metrics**

```yaml
- job_name: 'prometheus-self'
  static_configs:
    - targets: ['localhost:9090']  # 原生支持

- job_name: 'coredns'
  static_configs:
    - targets: ['coredns:9153']  # 原生支持

- job_name: 'etcd'
  static_configs:
    - targets: ['etcd:2379']  # 原生支持

- job_name: 'kubernetes-apiserver'
  static_configs:
    - targets: ['kubernetes:443']  # 原生支持
```

##  **需要 Exporter**

```yaml
# MySQL（需要 exporter）
- job_name: 'mysql'
  static_configs:
    - targets: ['mysql-exporter:9104']  # 不是 MySQL 本身

# Redis（需要 exporter）
- job_name: 'redis'
  static_configs:
    - targets: ['redis-exporter:9121']  # 不是 Redis 本身

# Nginx（需要 exporter 或 module）
- job_name: 'nginx'
  static_configs:
    - targets: ['nginx-exporter:9113']  # 不是 Nginx 本身
    # 或者如果使用 nginx-module-vts:
    # targets: ['nginx:9913']
```



## 实际部署示例

### 场景1：监控外部 MySQL 数据库

```bash
# 1. 部署 mysqld_exporter
docker run -d --name mysql-exporter \
  -p 9104:9104 \
  -e DATA_SOURCE_NAME="exporter:password@(mysql-server:3306)/" \
  prom/mysqld-exporter

# 2. Prometheus 配置
cat >> prometheus.yml <<EOF
- job_name: 'external-mysql'
  static_configs:
    - targets: ['mysql-exporter-host:9104']
EOF
```



### 场景2：监控自带 metrics 的服务

```bash
# CoreDNS（自带 metrics）
# 无需额外部署，直接配置
cat >> prometheus.yml <<EOF
- job_name: 'coredns'
  static_configs:
    - targets: ['10.96.0.10:9153']
EOF
```



## 快速检查脚本

```bash
#!/bin/bash
# 检查服务是否提供 Prometheus metrics

check_service() {
    local name=$1
    local host=$2
    local port=$3
    
    echo -n "检查 $name ($host:$port)... "
    
    if curl -s "http://${host}:${port}/metrics" 2>/dev/null | grep -q "prometheus"; then
        echo "✅ 原生支持"
    elif curl -s "http://${host}:${port}/metrics" 2>/dev/null | head -1 | grep -q "^[a-zA-Z_]"; then
        echo "✅ 提供 metrics（可能是 Prometheus 格式）"
    else
        echo "❌ 需要 exporter"
    fi
}

# 测试常见服务
check_service "Prometheus自身" "localhost" "9090"
check_service "node-exporter" "localhost" "9100"
check_service "cAdvisor" "localhost" "8080"
```